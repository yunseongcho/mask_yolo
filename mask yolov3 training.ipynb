{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"mask yolov3 training.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"position":{"height":"788px","left":"1554px","right":"20px","top":"120px","width":"346px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"hSZSB6lWZTXf"},"source":["# 패키지 설치 및 드라이브 마운트"],"id":"hSZSB6lWZTXf"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"930zXiioaaWk","executionInfo":{"status":"ok","timestamp":1616745546359,"user_tz":-540,"elapsed":7021,"user":{"displayName":"yunseong cho","photoUrl":"","userId":"12915842808143539986"}},"outputId":"580d46e0-c99c-4fdf-f115-d319ed16e24c"},"source":["!pip install pillow==6.2.2\n","!pip install tqdm\n","!pip install terminaltables"],"id":"930zXiioaaWk","execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pillow==6.2.2 in /usr/local/lib/python3.7/dist-packages (6.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mmpbtcD6ad41"},"source":["패키지 설치 시 `RESTART RUNTIME` 버튼이 나온다면 한 번 RESTART 시켜주고 다시 실행한다."],"id":"mmpbtcD6ad41"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PYA0X94qnCX","executionInfo":{"status":"ok","timestamp":1616745566000,"user_tz":-540,"elapsed":24293,"user":{"displayName":"yunseong cho","photoUrl":"","userId":"12915842808143539986"}},"outputId":"2f6ea37f-9c9f-4588-ff9e-fda5261a84ee"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"id":"7PYA0X94qnCX","execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YVBmYTAqxcG","executionInfo":{"status":"ok","timestamp":1616745566954,"user_tz":-540,"elapsed":909,"user":{"displayName":"yunseong cho","photoUrl":"","userId":"12915842808143539986"}},"outputId":"a4e4288f-1a09-4553-e413-efff65c25d0e"},"source":["import os\n","os.chdir('/content/gdrive/My Drive/mask-detection-yolov3')\n","os.listdir('/content/gdrive/My Drive/mask-detection-yolov3')"],"id":"_YVBmYTAqxcG","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['validate.py',\n"," '.gitignore',\n"," 'image_detect.py',\n"," 'models.py',\n"," 'cam_detect.py',\n"," 'requirements.txt',\n"," 'train.py',\n"," 'video_detect.py',\n"," 'data',\n"," '.idea',\n"," 'weights',\n"," 'config',\n"," '.git',\n"," 'testing',\n"," 'utils',\n"," '__pycache__',\n"," 'checkpoints',\n"," 'mask yolov3 testing.ipynb',\n"," 'mask yolov3 training.ipynb']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"D4SLggliZmnr"},"source":["# Training"],"id":"D4SLggliZmnr"},{"cell_type":"markdown","metadata":{"id":"nXbE6T80ZpBI"},"source":["## Package import"],"id":"nXbE6T80ZpBI"},{"cell_type":"code","metadata":{"id":"ll48jdxOql1n","executionInfo":{"status":"ok","timestamp":1616745594990,"user_tz":-540,"elapsed":5549,"user":{"displayName":"yunseong cho","photoUrl":"","userId":"12915842808143539986"}}},"source":["from __future__ import division\n","\n","from models import Darknet\n","from utils.utils import load_classes, weights_init_normal\n","from utils.datasets import ListDataset\n","from utils.parse_config import parse_data_config\n","from validate import evaluate\n","\n","from terminaltables import AsciiTable\n","\n","import os\n","import time\n","import argparse\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","\n","import warnings\n","import easydict\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","# from utils.logger import *"],"id":"ll48jdxOql1n","execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fgTIe3BNZuaq"},"source":["## Training Option Setting\n","Training Option을 정해준다. 필요한 몇 가지 옵션을 설명하면, epoch은 Training 데이터셋을 몇 번 반복해서 학습할 것인가를 말하며 batch_size는 한 번에 학습할 이미지의 갯수이다. pretrained_weights는 기학습된 모델의 weights 경로이며, checkpoint_interval은 몇 epoch 마다 학습한 모델을 저장할 것인지를 말하며, evaluation_interval은 몇 epoch 마다 모델을 validation set으로 평가할 것인지를 말한다.\n","\n","이번 실습에서는 시간 상 30 epoch까지 학습한 모델을 40 epoch까지 학습하는 training을 진행하려고 한다."],"id":"fgTIe3BNZuaq"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VxZBSk1tql1t","executionInfo":{"status":"ok","timestamp":1616745812867,"user_tz":-540,"elapsed":641,"user":{"displayName":"yunseong cho","photoUrl":"","userId":"12915842808143539986"}},"outputId":"1d0a6705-4298-425d-973c-bba607925c41"},"source":["opt = easydict.EasyDict({ \n","    'epochs': 10, \n","    'batch_size': 8, \n","    'gradient_accumulations': 2, \n","    'model_def': \"config/yolov3_mask.cfg\", \n","    'data_config': \"config/mask_dataset.data\",\n","    'pretrained_weights': \"checkpoints/yolov3_ckpt_30.pth\", # weights/yolov3.weights\n","    \"n_cpu\": 8,\n","    'img_size': 416,\n","    'checkpoint_interval': 10,\n","    'evaluation_interval': 5,\n","    'compute_map': True,\n","    'multiscale_training': True\n","})\n","print(opt)\n","# logger = Logger(\"logs\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# gpu를 사용가능하면 device에 cuda를 저장한다. \n","\n","os.makedirs(\"checkpoints\", exist_ok=True)\n","# checkpoints 폴더를 생성"],"id":"VxZBSk1tql1t","execution_count":6,"outputs":[{"output_type":"stream","text":["{'epochs': 10, 'batch_size': 8, 'gradient_accumulations': 2, 'model_def': 'config/yolov3_mask.cfg', 'data_config': 'config/mask_dataset.data', 'pretrained_weights': 'checkpoints/yolov3_ckpt_30.pth', 'n_cpu': 8, 'img_size': 416, 'checkpoint_interval': 10, 'evaluation_interval': 5, 'compute_map': True, 'multiscale_training': True}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vm5VQajUZ5dC"},"source":["## 데이터와 모델 로딩"],"id":"vm5VQajUZ5dC"},{"cell_type":"code","metadata":{"id":"Pq6o1CR1ql1u","executionInfo":{"status":"ok","timestamp":1616745834148,"user_tz":-540,"elapsed":19673,"user":{"displayName":"yunseong cho","photoUrl":"","userId":"12915842808143539986"}}},"source":["# 데이터셋의 경로와 클래스의 이름 등을 가져온다.\n","data_config = parse_data_config(opt.data_config)\n","train_path = data_config[\"train\"]\n","valid_path = data_config[\"valid\"]\n","class_names = load_classes(data_config[\"names\"])\n","\n","# dataset의 경로를 통해 ListDataset(dataset을 상속받은 class) 인스턴스를 만들고 이를 쉽게 가져올 수 있는 dataloader를 만든다.\n","dataset = ListDataset(train_path, augment=True, multiscale=opt.multiscale_training)\n","dataloader = torch.utils.data.DataLoader(\n","    dataset,\n","    batch_size=opt.batch_size,\n","    shuffle=True,\n","    num_workers=opt.n_cpu,\n","    pin_memory=True,\n","    collate_fn=dataset.collate_fn,\n",")\n","\n","# model을 정해준다. model 폴더에서 Darknet class 내에 yolov3 모델이 저장되어 있다. 모델에 관한 자세한 사항은 Darknet을 참고하자.\n","model = Darknet(opt.model_def).to(device)\n","model.apply(weights_init_normal)\n","\n","# pretrained_weights를 load한다.\n","if opt.pretrained_weights:\n","    if opt.pretrained_weights.endswith(\".pth\"):\n","        model.load_state_dict(torch.load(opt.pretrained_weights))\n","    else:\n","        model.load_darknet_weights(opt.pretrained_weights)"],"id":"Pq6o1CR1ql1u","execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pc-Ru1cWk__7"},"source":["## Training"],"id":"pc-Ru1cWk__7"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbbCmiuyql1w","scrolled":true,"outputId":"b66d3d1c-b5dc-4433-d8d0-ed913f5b2d24"},"source":["optimizer = torch.optim.Adam(model.parameters()) # Adam optimizer를 사용하며 model의 parameter를 인자로 넣어준다.\n","\n","# to get mAP\n","to_get_mAP = None\n","\n","for epoch in range(opt.epochs): # 미리 설정한 epoch 만큼 반복\n","    model.train()\n","    start_time = time.time()\n","    epoch += 31 # 31~40 epoch\n","    for batch_i, (_, imgs, targets) in enumerate(dataloader): # dataloader 에서 batch_size 만큼씩 학습.\n","        batches_done = len(dataloader) * epoch + batch_i\n","\n","        imgs = Variable(imgs.to(device))\n","        targets = Variable(targets.to(device), requires_grad=False)\n","\n","        loss, outputs = model(imgs, targets) # model에서 부터 loss 계산\n","        loss.backward() # loss에 대한 gradient 계산\n","\n","        if batches_done % opt.gradient_accumulations:\n","            optimizer.step() # 학습 진행\n","            optimizer.zero_grad() # gradient를 0으로 만든다.\n","\n","\n","        log_str = \"---- [Epoch %d/%d, Batch %d/%d] ----\" % (epoch, opt.epochs + 30, batch_i, len(dataloader))\n","        log_str += f\"Total loss {loss.item()}\"\n","        print(log_str)\n","\n","        model.seen += imgs.size(0)\n","\n","    if epoch % opt.evaluation_interval == 0: # validation set에 대해 mAP 성능평가\n","        try:\n","            print(\"\\n---- Evaluating Model ----\")\n","            # Evaluate the model on the validation set\n","            precision, recall, AP, f1, ap_class = evaluate(\n","                model,\n","                path=valid_path,\n","                iou_thres=0.5,\n","                conf_thres=0.5,\n","                nms_thres=0.5,\n","                img_size=opt.img_size,\n","                batch_size=4,\n","            )\n","            evaluation_metrics = [\n","                (\"val_precision\", precision.mean()),\n","                (\"val_recall\", recall.mean()),\n","                (\"val_mAP\", AP.mean()),\n","                (\"val_f1\", f1.mean()),\n","            ]\n","            # logger.list_of_scalars_summary(evaluation_metrics, epoch)\n","\n","            # Print class APs and mAP\n","            ap_table = [[\"Index\", \"Class name\", \"AP\"]]\n","            for i, c in enumerate(ap_class):\n","                ap_table += [[c, class_names[c], \"%.5f\" % AP[i]]]\n","            print(AsciiTable(ap_table).table)\n","            print(f\"---- mAP {AP.mean()}\")\n","            to_get_mAP = AP.mean()\n","        except:\n","            to_get_mAP = 999999999999\n","\n","    if epoch % opt.checkpoint_interval == 0: # checkpoint_interval 마다 model weight 저장.\n","        torch.save(model.state_dict(), \"checkpoints/yolov3_ckpt_{0}.pth\".format(epoch))"],"id":"bbbCmiuyql1w","execution_count":null,"outputs":[{"output_type":"stream","text":["---- [Epoch 31/40, Batch 0/340] ----Total loss 1.0498112440109253\n","---- [Epoch 31/40, Batch 1/340] ----Total loss 0.9420675039291382\n","---- [Epoch 31/40, Batch 2/340] ----Total loss 3.4257636070251465\n","---- [Epoch 31/40, Batch 3/340] ----Total loss 2.3439600467681885\n","---- [Epoch 31/40, Batch 4/340] ----Total loss 3.008242130279541\n","---- [Epoch 31/40, Batch 5/340] ----Total loss 2.772014856338501\n","---- [Epoch 31/40, Batch 6/340] ----Total loss 5.922479629516602\n","---- [Epoch 31/40, Batch 7/340] ----Total loss 1.9322395324707031\n","---- [Epoch 31/40, Batch 8/340] ----Total loss 1.5293818712234497\n","---- [Epoch 31/40, Batch 9/340] ----Total loss 1.652246356010437\n","---- [Epoch 31/40, Batch 10/340] ----Total loss 1.0404229164123535\n","---- [Epoch 31/40, Batch 11/340] ----Total loss 1.7698338031768799\n","---- [Epoch 31/40, Batch 12/340] ----Total loss 2.033287525177002\n","---- [Epoch 31/40, Batch 13/340] ----Total loss 5.161789894104004\n","---- [Epoch 31/40, Batch 14/340] ----Total loss 4.551518440246582\n","---- [Epoch 31/40, Batch 15/340] ----Total loss 5.058561325073242\n","---- [Epoch 31/40, Batch 16/340] ----Total loss 2.0081279277801514\n","---- [Epoch 31/40, Batch 17/340] ----Total loss 1.2219889163970947\n","---- [Epoch 31/40, Batch 18/340] ----Total loss 2.2464840412139893\n","---- [Epoch 31/40, Batch 19/340] ----Total loss 1.6665304899215698\n","---- [Epoch 31/40, Batch 20/340] ----Total loss 3.726138114929199\n","---- [Epoch 31/40, Batch 21/340] ----Total loss 2.85656476020813\n","---- [Epoch 31/40, Batch 22/340] ----Total loss 3.0078253746032715\n","---- [Epoch 31/40, Batch 23/340] ----Total loss 2.0040600299835205\n","---- [Epoch 31/40, Batch 24/340] ----Total loss 1.6380558013916016\n","---- [Epoch 31/40, Batch 25/340] ----Total loss 1.579551339149475\n","---- [Epoch 31/40, Batch 26/340] ----Total loss 1.7380331754684448\n","---- [Epoch 31/40, Batch 27/340] ----Total loss 1.7967584133148193\n","---- [Epoch 31/40, Batch 28/340] ----Total loss 1.548421025276184\n","---- [Epoch 31/40, Batch 29/340] ----Total loss 3.105991840362549\n","---- [Epoch 31/40, Batch 30/340] ----Total loss 2.187098741531372\n","---- [Epoch 31/40, Batch 31/340] ----Total loss 1.8880525827407837\n","---- [Epoch 31/40, Batch 32/340] ----Total loss 1.640057921409607\n","---- [Epoch 31/40, Batch 33/340] ----Total loss 3.538477897644043\n","---- [Epoch 31/40, Batch 34/340] ----Total loss 1.839141607284546\n","---- [Epoch 31/40, Batch 35/340] ----Total loss 1.9575865268707275\n","---- [Epoch 31/40, Batch 36/340] ----Total loss 1.8233036994934082\n","---- [Epoch 31/40, Batch 37/340] ----Total loss 2.9059109687805176\n","---- [Epoch 31/40, Batch 38/340] ----Total loss 2.9597578048706055\n","---- [Epoch 31/40, Batch 39/340] ----Total loss 2.0300028324127197\n","---- [Epoch 31/40, Batch 40/340] ----Total loss 1.5762183666229248\n","---- [Epoch 31/40, Batch 41/340] ----Total loss 2.093663215637207\n","---- [Epoch 31/40, Batch 42/340] ----Total loss 2.048318862915039\n","---- [Epoch 31/40, Batch 43/340] ----Total loss 2.1841821670532227\n","---- [Epoch 31/40, Batch 44/340] ----Total loss 1.6777138710021973\n","---- [Epoch 31/40, Batch 45/340] ----Total loss 2.654705762863159\n","---- [Epoch 31/40, Batch 46/340] ----Total loss 1.6337263584136963\n","---- [Epoch 31/40, Batch 47/340] ----Total loss 1.4334385395050049\n","---- [Epoch 31/40, Batch 48/340] ----Total loss 2.481022357940674\n","---- [Epoch 31/40, Batch 49/340] ----Total loss 1.4769235849380493\n","---- [Epoch 31/40, Batch 50/340] ----Total loss 1.1264333724975586\n","---- [Epoch 31/40, Batch 51/340] ----Total loss 1.500636339187622\n","---- [Epoch 31/40, Batch 52/340] ----Total loss 1.1598024368286133\n","---- [Epoch 31/40, Batch 53/340] ----Total loss 2.2828588485717773\n","---- [Epoch 31/40, Batch 54/340] ----Total loss 2.2363972663879395\n","---- [Epoch 31/40, Batch 55/340] ----Total loss 4.406574726104736\n","---- [Epoch 31/40, Batch 56/340] ----Total loss 1.2829574346542358\n","---- [Epoch 31/40, Batch 57/340] ----Total loss 1.2587676048278809\n","---- [Epoch 31/40, Batch 58/340] ----Total loss 1.628868579864502\n","---- [Epoch 31/40, Batch 59/340] ----Total loss 1.8988600969314575\n","---- [Epoch 31/40, Batch 60/340] ----Total loss 2.3295083045959473\n","---- [Epoch 31/40, Batch 61/340] ----Total loss 2.5079774856567383\n","---- [Epoch 31/40, Batch 62/340] ----Total loss 1.0486973524093628\n","---- [Epoch 31/40, Batch 63/340] ----Total loss 2.878446102142334\n","---- [Epoch 31/40, Batch 64/340] ----Total loss 1.5483300685882568\n","---- [Epoch 31/40, Batch 65/340] ----Total loss 1.9966026544570923\n","---- [Epoch 31/40, Batch 66/340] ----Total loss 1.4278147220611572\n","---- [Epoch 31/40, Batch 67/340] ----Total loss 1.1811023950576782\n","---- [Epoch 31/40, Batch 68/340] ----Total loss 1.842214822769165\n","---- [Epoch 31/40, Batch 69/340] ----Total loss 1.3638081550598145\n","---- [Epoch 31/40, Batch 70/340] ----Total loss 2.7445130348205566\n","---- [Epoch 31/40, Batch 71/340] ----Total loss 1.9478495121002197\n","---- [Epoch 31/40, Batch 72/340] ----Total loss 1.439107060432434\n","---- [Epoch 31/40, Batch 73/340] ----Total loss 1.959296703338623\n","---- [Epoch 31/40, Batch 74/340] ----Total loss 1.5676684379577637\n","---- [Epoch 31/40, Batch 75/340] ----Total loss 1.7279744148254395\n","---- [Epoch 31/40, Batch 76/340] ----Total loss 3.5205986499786377\n","---- [Epoch 31/40, Batch 77/340] ----Total loss 1.5932294130325317\n","---- [Epoch 31/40, Batch 78/340] ----Total loss 0.744384765625\n","---- [Epoch 31/40, Batch 79/340] ----Total loss 1.4124518632888794\n","---- [Epoch 31/40, Batch 80/340] ----Total loss 1.319653034210205\n","---- [Epoch 31/40, Batch 81/340] ----Total loss 3.4545793533325195\n","---- [Epoch 31/40, Batch 82/340] ----Total loss 2.45426607131958\n","---- [Epoch 31/40, Batch 83/340] ----Total loss 1.4219098091125488\n","---- [Epoch 31/40, Batch 84/340] ----Total loss 1.591941237449646\n","---- [Epoch 31/40, Batch 85/340] ----Total loss 1.150139331817627\n","---- [Epoch 31/40, Batch 86/340] ----Total loss 1.2148842811584473\n","---- [Epoch 31/40, Batch 87/340] ----Total loss 1.5800317525863647\n","---- [Epoch 31/40, Batch 88/340] ----Total loss 2.6314280033111572\n","---- [Epoch 31/40, Batch 89/340] ----Total loss 1.3809343576431274\n","---- [Epoch 31/40, Batch 90/340] ----Total loss 1.6041462421417236\n","---- [Epoch 31/40, Batch 91/340] ----Total loss 1.7285387516021729\n","---- [Epoch 31/40, Batch 92/340] ----Total loss 4.227147102355957\n","---- [Epoch 31/40, Batch 93/340] ----Total loss 2.5221829414367676\n","---- [Epoch 31/40, Batch 94/340] ----Total loss 1.885352373123169\n","---- [Epoch 31/40, Batch 95/340] ----Total loss 2.026607036590576\n","---- [Epoch 31/40, Batch 96/340] ----Total loss 1.3777724504470825\n","---- [Epoch 31/40, Batch 97/340] ----Total loss 4.322658538818359\n","---- [Epoch 31/40, Batch 98/340] ----Total loss 2.420600652694702\n","---- [Epoch 31/40, Batch 99/340] ----Total loss 2.3907055854797363\n","---- [Epoch 31/40, Batch 100/340] ----Total loss 3.2049503326416016\n","---- [Epoch 31/40, Batch 101/340] ----Total loss 1.9785234928131104\n","---- [Epoch 31/40, Batch 102/340] ----Total loss 1.234525442123413\n","---- [Epoch 31/40, Batch 103/340] ----Total loss 2.180955410003662\n","---- [Epoch 31/40, Batch 104/340] ----Total loss 2.874946117401123\n","---- [Epoch 31/40, Batch 105/340] ----Total loss 1.562587022781372\n","---- [Epoch 31/40, Batch 106/340] ----Total loss 1.747675895690918\n","---- [Epoch 31/40, Batch 107/340] ----Total loss 1.9397876262664795\n","---- [Epoch 31/40, Batch 108/340] ----Total loss 5.26767635345459\n","---- [Epoch 31/40, Batch 109/340] ----Total loss 1.4121382236480713\n","---- [Epoch 31/40, Batch 110/340] ----Total loss 1.8206263780593872\n","---- [Epoch 31/40, Batch 111/340] ----Total loss 2.268327236175537\n","---- [Epoch 31/40, Batch 112/340] ----Total loss 1.3274199962615967\n","---- [Epoch 31/40, Batch 113/340] ----Total loss 1.3765499591827393\n","---- [Epoch 31/40, Batch 114/340] ----Total loss 2.5923242568969727\n","---- [Epoch 31/40, Batch 115/340] ----Total loss 1.3644297122955322\n","---- [Epoch 31/40, Batch 116/340] ----Total loss 1.1103074550628662\n","---- [Epoch 31/40, Batch 117/340] ----Total loss 1.8211220502853394\n","---- [Epoch 31/40, Batch 118/340] ----Total loss 3.156184434890747\n","---- [Epoch 31/40, Batch 119/340] ----Total loss 2.685943365097046\n","---- [Epoch 31/40, Batch 120/340] ----Total loss 1.2611327171325684\n","---- [Epoch 31/40, Batch 121/340] ----Total loss 1.6394652128219604\n","---- [Epoch 31/40, Batch 122/340] ----Total loss 1.1813746690750122\n","---- [Epoch 31/40, Batch 123/340] ----Total loss 2.3150904178619385\n","---- [Epoch 31/40, Batch 124/340] ----Total loss 2.5920023918151855\n","---- [Epoch 31/40, Batch 125/340] ----Total loss 1.607191801071167\n","---- [Epoch 31/40, Batch 126/340] ----Total loss 2.5013651847839355\n","---- [Epoch 31/40, Batch 127/340] ----Total loss 2.175976276397705\n","---- [Epoch 31/40, Batch 128/340] ----Total loss 5.569087505340576\n","---- [Epoch 31/40, Batch 129/340] ----Total loss 1.963590383529663\n","---- [Epoch 31/40, Batch 130/340] ----Total loss 2.1248526573181152\n","---- [Epoch 31/40, Batch 131/340] ----Total loss 1.5460453033447266\n","---- [Epoch 31/40, Batch 132/340] ----Total loss 2.212808847427368\n","---- [Epoch 31/40, Batch 133/340] ----Total loss 3.682159423828125\n","---- [Epoch 31/40, Batch 134/340] ----Total loss 2.0183560848236084\n","---- [Epoch 31/40, Batch 135/340] ----Total loss 2.397911787033081\n","---- [Epoch 31/40, Batch 136/340] ----Total loss 1.582946538925171\n","---- [Epoch 31/40, Batch 137/340] ----Total loss 1.477110505104065\n","---- [Epoch 31/40, Batch 138/340] ----Total loss 3.3383450508117676\n","---- [Epoch 31/40, Batch 139/340] ----Total loss 2.0428977012634277\n","---- [Epoch 31/40, Batch 140/340] ----Total loss 2.547720193862915\n","---- [Epoch 31/40, Batch 141/340] ----Total loss 1.235835075378418\n","---- [Epoch 31/40, Batch 142/340] ----Total loss 1.8349106311798096\n","---- [Epoch 31/40, Batch 143/340] ----Total loss 1.7602462768554688\n","---- [Epoch 31/40, Batch 144/340] ----Total loss 1.9624015092849731\n","---- [Epoch 31/40, Batch 145/340] ----Total loss 3.4353556632995605\n","---- [Epoch 31/40, Batch 146/340] ----Total loss 2.522735595703125\n","---- [Epoch 31/40, Batch 147/340] ----Total loss 6.106326103210449\n","---- [Epoch 31/40, Batch 148/340] ----Total loss 1.4346836805343628\n","---- [Epoch 31/40, Batch 149/340] ----Total loss 1.613733172416687\n","---- [Epoch 31/40, Batch 150/340] ----Total loss 2.611959934234619\n","---- [Epoch 31/40, Batch 151/340] ----Total loss 1.7318470478057861\n","---- [Epoch 31/40, Batch 152/340] ----Total loss 2.4338126182556152\n","---- [Epoch 31/40, Batch 153/340] ----Total loss 1.672745704650879\n","---- [Epoch 31/40, Batch 154/340] ----Total loss 1.5141816139221191\n","---- [Epoch 31/40, Batch 155/340] ----Total loss 1.5620999336242676\n","---- [Epoch 31/40, Batch 156/340] ----Total loss 1.6752903461456299\n","---- [Epoch 31/40, Batch 157/340] ----Total loss 2.284984827041626\n","---- [Epoch 31/40, Batch 158/340] ----Total loss 1.2332555055618286\n","---- [Epoch 31/40, Batch 159/340] ----Total loss 2.067868947982788\n","---- [Epoch 31/40, Batch 160/340] ----Total loss 1.4055674076080322\n","---- [Epoch 31/40, Batch 161/340] ----Total loss 1.3876965045928955\n","---- [Epoch 31/40, Batch 162/340] ----Total loss 1.4512065649032593\n","---- [Epoch 31/40, Batch 163/340] ----Total loss 1.956475019454956\n","---- [Epoch 31/40, Batch 164/340] ----Total loss 2.783663749694824\n","---- [Epoch 31/40, Batch 165/340] ----Total loss 4.326300621032715\n","---- [Epoch 31/40, Batch 166/340] ----Total loss 2.3739285469055176\n","---- [Epoch 31/40, Batch 167/340] ----Total loss 1.56642746925354\n","---- [Epoch 31/40, Batch 168/340] ----Total loss 2.049147129058838\n","---- [Epoch 31/40, Batch 169/340] ----Total loss 1.9013084173202515\n","---- [Epoch 31/40, Batch 170/340] ----Total loss 1.2949063777923584\n","---- [Epoch 31/40, Batch 171/340] ----Total loss 2.02799654006958\n","---- [Epoch 31/40, Batch 172/340] ----Total loss 1.6957902908325195\n","---- [Epoch 31/40, Batch 173/340] ----Total loss 1.3513376712799072\n","---- [Epoch 31/40, Batch 174/340] ----Total loss 1.1168620586395264\n","---- [Epoch 31/40, Batch 175/340] ----Total loss 1.8207316398620605\n","---- [Epoch 31/40, Batch 176/340] ----Total loss 1.1088275909423828\n","---- [Epoch 31/40, Batch 177/340] ----Total loss 0.9718707799911499\n","---- [Epoch 31/40, Batch 178/340] ----Total loss 1.1997214555740356\n","---- [Epoch 31/40, Batch 179/340] ----Total loss 1.0513215065002441\n","---- [Epoch 31/40, Batch 180/340] ----Total loss 1.668215274810791\n","---- [Epoch 31/40, Batch 181/340] ----Total loss 2.75246262550354\n","---- [Epoch 31/40, Batch 182/340] ----Total loss 2.1086387634277344\n","---- [Epoch 31/40, Batch 183/340] ----Total loss 1.1499035358428955\n","---- [Epoch 31/40, Batch 184/340] ----Total loss 1.4364959001541138\n","---- [Epoch 31/40, Batch 185/340] ----Total loss 2.9935383796691895\n","---- [Epoch 31/40, Batch 186/340] ----Total loss 2.2494306564331055\n","---- [Epoch 31/40, Batch 187/340] ----Total loss 2.0981831550598145\n","---- [Epoch 31/40, Batch 188/340] ----Total loss 2.1498751640319824\n","---- [Epoch 31/40, Batch 189/340] ----Total loss 2.5190815925598145\n","---- [Epoch 31/40, Batch 190/340] ----Total loss 1.7898304462432861\n","---- [Epoch 31/40, Batch 191/340] ----Total loss 1.8464452028274536\n","---- [Epoch 31/40, Batch 192/340] ----Total loss 1.8578853607177734\n","---- [Epoch 31/40, Batch 193/340] ----Total loss 1.4632220268249512\n","---- [Epoch 31/40, Batch 194/340] ----Total loss 1.4681402444839478\n","---- [Epoch 31/40, Batch 195/340] ----Total loss 1.5624186992645264\n","---- [Epoch 31/40, Batch 196/340] ----Total loss 2.5571999549865723\n","---- [Epoch 31/40, Batch 197/340] ----Total loss 2.9091286659240723\n","---- [Epoch 31/40, Batch 198/340] ----Total loss 2.081873655319214\n","---- [Epoch 31/40, Batch 199/340] ----Total loss 1.4651087522506714\n","---- [Epoch 31/40, Batch 200/340] ----Total loss 2.7323288917541504\n","---- [Epoch 31/40, Batch 201/340] ----Total loss 1.2747358083724976\n","---- [Epoch 31/40, Batch 202/340] ----Total loss 1.1093418598175049\n","---- [Epoch 31/40, Batch 203/340] ----Total loss 1.8101197481155396\n","---- [Epoch 31/40, Batch 204/340] ----Total loss 1.5436089038848877\n","---- [Epoch 31/40, Batch 205/340] ----Total loss 2.40207839012146\n","---- [Epoch 31/40, Batch 206/340] ----Total loss 1.1877882480621338\n","---- [Epoch 31/40, Batch 207/340] ----Total loss 1.3405320644378662\n","---- [Epoch 31/40, Batch 208/340] ----Total loss 1.518376111984253\n","---- [Epoch 31/40, Batch 209/340] ----Total loss 1.5834060907363892\n","---- [Epoch 31/40, Batch 210/340] ----Total loss 1.8034738302230835\n","---- [Epoch 31/40, Batch 211/340] ----Total loss 1.2061424255371094\n","---- [Epoch 31/40, Batch 212/340] ----Total loss 1.7011492252349854\n","---- [Epoch 31/40, Batch 213/340] ----Total loss 2.281162738800049\n","---- [Epoch 31/40, Batch 214/340] ----Total loss 1.4685616493225098\n","---- [Epoch 31/40, Batch 215/340] ----Total loss 1.5359221696853638\n","---- [Epoch 31/40, Batch 216/340] ----Total loss 2.0147342681884766\n","---- [Epoch 31/40, Batch 217/340] ----Total loss 1.4255216121673584\n","---- [Epoch 31/40, Batch 218/340] ----Total loss 0.9678462147712708\n","---- [Epoch 31/40, Batch 219/340] ----Total loss 3.220322608947754\n","---- [Epoch 31/40, Batch 220/340] ----Total loss 1.1998645067214966\n","---- [Epoch 31/40, Batch 221/340] ----Total loss 1.644601583480835\n","---- [Epoch 31/40, Batch 222/340] ----Total loss 1.4431759119033813\n","---- [Epoch 31/40, Batch 223/340] ----Total loss 2.4723830223083496\n","---- [Epoch 31/40, Batch 224/340] ----Total loss 2.2572407722473145\n","---- [Epoch 31/40, Batch 225/340] ----Total loss 1.1692445278167725\n","---- [Epoch 31/40, Batch 226/340] ----Total loss 1.2047005891799927\n","---- [Epoch 31/40, Batch 227/340] ----Total loss 2.237304210662842\n","---- [Epoch 31/40, Batch 228/340] ----Total loss 2.057523727416992\n","---- [Epoch 31/40, Batch 229/340] ----Total loss 1.7968461513519287\n","---- [Epoch 31/40, Batch 230/340] ----Total loss 1.3408701419830322\n","---- [Epoch 31/40, Batch 231/340] ----Total loss 1.4351942539215088\n","---- [Epoch 31/40, Batch 232/340] ----Total loss 1.7890710830688477\n","---- [Epoch 31/40, Batch 233/340] ----Total loss 1.0093488693237305\n","---- [Epoch 31/40, Batch 234/340] ----Total loss 1.2508577108383179\n","---- [Epoch 31/40, Batch 235/340] ----Total loss 2.032538414001465\n","---- [Epoch 31/40, Batch 236/340] ----Total loss 1.005348801612854\n","---- [Epoch 31/40, Batch 237/340] ----Total loss 2.1403708457946777\n","---- [Epoch 31/40, Batch 238/340] ----Total loss 2.0110392570495605\n","---- [Epoch 31/40, Batch 239/340] ----Total loss 1.3610961437225342\n","---- [Epoch 31/40, Batch 240/340] ----Total loss 4.364151477813721\n","---- [Epoch 31/40, Batch 241/340] ----Total loss 3.379681348800659\n","---- [Epoch 31/40, Batch 242/340] ----Total loss 1.4107556343078613\n","---- [Epoch 31/40, Batch 243/340] ----Total loss 1.5817077159881592\n","---- [Epoch 31/40, Batch 244/340] ----Total loss 1.3842798471450806\n","---- [Epoch 31/40, Batch 245/340] ----Total loss 2.028679132461548\n","---- [Epoch 31/40, Batch 246/340] ----Total loss 1.5957813262939453\n","---- [Epoch 31/40, Batch 247/340] ----Total loss 1.8677523136138916\n","---- [Epoch 31/40, Batch 248/340] ----Total loss 2.1476221084594727\n","---- [Epoch 31/40, Batch 249/340] ----Total loss 1.9157018661499023\n","---- [Epoch 31/40, Batch 250/340] ----Total loss 2.0592808723449707\n","---- [Epoch 31/40, Batch 251/340] ----Total loss 1.6636964082717896\n","---- [Epoch 31/40, Batch 252/340] ----Total loss 1.8718822002410889\n","---- [Epoch 31/40, Batch 253/340] ----Total loss 1.5423462390899658\n","---- [Epoch 31/40, Batch 254/340] ----Total loss 1.5646462440490723\n","---- [Epoch 31/40, Batch 255/340] ----Total loss 1.4428503513336182\n","---- [Epoch 31/40, Batch 256/340] ----Total loss 1.7577950954437256\n","---- [Epoch 31/40, Batch 257/340] ----Total loss 4.058122634887695\n","---- [Epoch 31/40, Batch 258/340] ----Total loss 1.3442809581756592\n","---- [Epoch 31/40, Batch 259/340] ----Total loss 1.6153905391693115\n","---- [Epoch 31/40, Batch 260/340] ----Total loss 1.542322039604187\n","---- [Epoch 31/40, Batch 261/340] ----Total loss 1.4965760707855225\n","---- [Epoch 31/40, Batch 262/340] ----Total loss 1.513620376586914\n","---- [Epoch 31/40, Batch 263/340] ----Total loss 1.3388853073120117\n","---- [Epoch 31/40, Batch 264/340] ----Total loss 1.3187150955200195\n","---- [Epoch 31/40, Batch 265/340] ----Total loss 1.2586195468902588\n","---- [Epoch 31/40, Batch 266/340] ----Total loss 2.0685765743255615\n","---- [Epoch 31/40, Batch 267/340] ----Total loss 1.7503759860992432\n","---- [Epoch 31/40, Batch 268/340] ----Total loss 1.4776182174682617\n","---- [Epoch 31/40, Batch 269/340] ----Total loss 3.008833169937134\n","---- [Epoch 31/40, Batch 270/340] ----Total loss 1.772370457649231\n","---- [Epoch 31/40, Batch 271/340] ----Total loss 3.179722309112549\n","---- [Epoch 31/40, Batch 272/340] ----Total loss 1.9772937297821045\n","---- [Epoch 31/40, Batch 273/340] ----Total loss 1.6404039859771729\n","---- [Epoch 31/40, Batch 274/340] ----Total loss 2.545015335083008\n","---- [Epoch 31/40, Batch 275/340] ----Total loss 1.6456527709960938\n","---- [Epoch 31/40, Batch 276/340] ----Total loss 1.6516462564468384\n","---- [Epoch 31/40, Batch 277/340] ----Total loss 1.5069994926452637\n","---- [Epoch 31/40, Batch 278/340] ----Total loss 1.5603880882263184\n","---- [Epoch 31/40, Batch 279/340] ----Total loss 1.931626319885254\n","---- [Epoch 31/40, Batch 280/340] ----Total loss 1.2808783054351807\n","---- [Epoch 31/40, Batch 281/340] ----Total loss 4.691922664642334\n","---- [Epoch 31/40, Batch 282/340] ----Total loss 2.1045756340026855\n","---- [Epoch 31/40, Batch 283/340] ----Total loss 1.2795214653015137\n","---- [Epoch 31/40, Batch 284/340] ----Total loss 1.6221565008163452\n","---- [Epoch 31/40, Batch 285/340] ----Total loss 4.8343658447265625\n","---- [Epoch 31/40, Batch 286/340] ----Total loss 2.8871445655822754\n","---- [Epoch 31/40, Batch 287/340] ----Total loss 1.3523426055908203\n","---- [Epoch 31/40, Batch 288/340] ----Total loss 1.3008681535720825\n","---- [Epoch 31/40, Batch 289/340] ----Total loss 1.9334099292755127\n","---- [Epoch 31/40, Batch 290/340] ----Total loss 2.0720410346984863\n","---- [Epoch 31/40, Batch 291/340] ----Total loss 1.9235389232635498\n","---- [Epoch 31/40, Batch 292/340] ----Total loss 2.1082193851470947\n","---- [Epoch 31/40, Batch 293/340] ----Total loss 1.8541277647018433\n","---- [Epoch 31/40, Batch 294/340] ----Total loss 1.1626173257827759\n","---- [Epoch 31/40, Batch 295/340] ----Total loss 2.1936097145080566\n","---- [Epoch 31/40, Batch 296/340] ----Total loss 2.2540204524993896\n","---- [Epoch 31/40, Batch 297/340] ----Total loss 1.5392842292785645\n","---- [Epoch 31/40, Batch 298/340] ----Total loss 2.234476089477539\n","---- [Epoch 31/40, Batch 299/340] ----Total loss 1.8230109214782715\n","---- [Epoch 31/40, Batch 300/340] ----Total loss 2.6682772636413574\n","---- [Epoch 31/40, Batch 301/340] ----Total loss 1.5109336376190186\n","---- [Epoch 31/40, Batch 302/340] ----Total loss 1.0818606615066528\n","---- [Epoch 31/40, Batch 303/340] ----Total loss 1.093501091003418\n","---- [Epoch 31/40, Batch 304/340] ----Total loss 2.2453293800354004\n","---- [Epoch 31/40, Batch 305/340] ----Total loss 1.9807827472686768\n","---- [Epoch 31/40, Batch 306/340] ----Total loss 1.5534892082214355\n","---- [Epoch 31/40, Batch 307/340] ----Total loss 2.2715768814086914\n","---- [Epoch 31/40, Batch 308/340] ----Total loss 7.255809783935547\n","---- [Epoch 31/40, Batch 309/340] ----Total loss 1.9353864192962646\n","---- [Epoch 31/40, Batch 310/340] ----Total loss 4.2384867668151855\n","---- [Epoch 31/40, Batch 311/340] ----Total loss 2.260329008102417\n","---- [Epoch 31/40, Batch 312/340] ----Total loss 2.228671073913574\n","---- [Epoch 31/40, Batch 313/340] ----Total loss 2.109630584716797\n","---- [Epoch 31/40, Batch 314/340] ----Total loss 3.3146581649780273\n","---- [Epoch 31/40, Batch 315/340] ----Total loss 1.9568109512329102\n","---- [Epoch 31/40, Batch 316/340] ----Total loss 2.3350906372070312\n","---- [Epoch 31/40, Batch 317/340] ----Total loss 1.3695682287216187\n","---- [Epoch 31/40, Batch 318/340] ----Total loss 2.331914186477661\n","---- [Epoch 31/40, Batch 319/340] ----Total loss 3.124541759490967\n","---- [Epoch 31/40, Batch 320/340] ----Total loss 5.113452434539795\n","---- [Epoch 31/40, Batch 321/340] ----Total loss 2.75351881980896\n","---- [Epoch 31/40, Batch 322/340] ----Total loss 2.1607980728149414\n","---- [Epoch 31/40, Batch 323/340] ----Total loss 3.383307695388794\n","---- [Epoch 31/40, Batch 324/340] ----Total loss 1.4464163780212402\n","---- [Epoch 31/40, Batch 325/340] ----Total loss 1.433964490890503\n","---- [Epoch 31/40, Batch 326/340] ----Total loss 1.5439164638519287\n","---- [Epoch 31/40, Batch 327/340] ----Total loss 1.4384369850158691\n","---- [Epoch 31/40, Batch 328/340] ----Total loss 1.6413459777832031\n","---- [Epoch 31/40, Batch 329/340] ----Total loss 1.7932326793670654\n","---- [Epoch 31/40, Batch 330/340] ----Total loss 2.4234156608581543\n","---- [Epoch 31/40, Batch 331/340] ----Total loss 3.4356374740600586\n","---- [Epoch 31/40, Batch 332/340] ----Total loss 1.5565279722213745\n","---- [Epoch 31/40, Batch 333/340] ----Total loss 2.49627423286438\n","---- [Epoch 31/40, Batch 334/340] ----Total loss 1.1163588762283325\n","---- [Epoch 31/40, Batch 335/340] ----Total loss 2.5453200340270996\n","---- [Epoch 31/40, Batch 336/340] ----Total loss 1.5578522682189941\n","---- [Epoch 31/40, Batch 337/340] ----Total loss 4.18726921081543\n","---- [Epoch 31/40, Batch 338/340] ----Total loss 1.2014621496200562\n","---- [Epoch 31/40, Batch 339/340] ----Total loss 2.2084157466888428\n","---- [Epoch 32/40, Batch 0/340] ----Total loss 1.4339475631713867\n","---- [Epoch 32/40, Batch 1/340] ----Total loss 2.0103647708892822\n","---- [Epoch 32/40, Batch 2/340] ----Total loss 1.4068567752838135\n","---- [Epoch 32/40, Batch 3/340] ----Total loss 1.0681856870651245\n","---- [Epoch 32/40, Batch 4/340] ----Total loss 1.3719804286956787\n","---- [Epoch 32/40, Batch 5/340] ----Total loss 0.9842609167098999\n","---- [Epoch 32/40, Batch 6/340] ----Total loss 0.9586983919143677\n","---- [Epoch 32/40, Batch 7/340] ----Total loss 2.934861183166504\n","---- [Epoch 32/40, Batch 8/340] ----Total loss 2.8887124061584473\n","---- [Epoch 32/40, Batch 9/340] ----Total loss 2.3139686584472656\n","---- [Epoch 32/40, Batch 10/340] ----Total loss 1.1599358320236206\n","---- [Epoch 32/40, Batch 11/340] ----Total loss 1.1650288105010986\n","---- [Epoch 32/40, Batch 12/340] ----Total loss 1.3848129510879517\n","---- [Epoch 32/40, Batch 13/340] ----Total loss 2.0665674209594727\n","---- [Epoch 32/40, Batch 14/340] ----Total loss 2.6980655193328857\n","---- [Epoch 32/40, Batch 15/340] ----Total loss 1.0428754091262817\n","---- [Epoch 32/40, Batch 16/340] ----Total loss 1.999215841293335\n","---- [Epoch 32/40, Batch 17/340] ----Total loss 0.9276162385940552\n","---- [Epoch 32/40, Batch 18/340] ----Total loss 1.7451038360595703\n","---- [Epoch 32/40, Batch 19/340] ----Total loss 1.3699114322662354\n","---- [Epoch 32/40, Batch 20/340] ----Total loss 1.1748250722885132\n","---- [Epoch 32/40, Batch 21/340] ----Total loss 1.524930477142334\n","---- [Epoch 32/40, Batch 22/340] ----Total loss 0.711268424987793\n","---- [Epoch 32/40, Batch 23/340] ----Total loss 1.5855183601379395\n","---- [Epoch 32/40, Batch 24/340] ----Total loss 1.7942514419555664\n","---- [Epoch 32/40, Batch 25/340] ----Total loss 1.561287760734558\n","---- [Epoch 32/40, Batch 26/340] ----Total loss 1.450711965560913\n","---- [Epoch 32/40, Batch 27/340] ----Total loss 1.3867897987365723\n","---- [Epoch 32/40, Batch 28/340] ----Total loss 1.314958095550537\n","---- [Epoch 32/40, Batch 29/340] ----Total loss 2.4863734245300293\n","---- [Epoch 32/40, Batch 30/340] ----Total loss 2.166203022003174\n","---- [Epoch 32/40, Batch 31/340] ----Total loss 1.195237398147583\n","---- [Epoch 32/40, Batch 32/340] ----Total loss 1.7154335975646973\n","---- [Epoch 32/40, Batch 33/340] ----Total loss 1.218895673751831\n","---- [Epoch 32/40, Batch 34/340] ----Total loss 1.316975474357605\n","---- [Epoch 32/40, Batch 35/340] ----Total loss 1.0611817836761475\n","---- [Epoch 32/40, Batch 36/340] ----Total loss 1.5336024761199951\n","---- [Epoch 32/40, Batch 37/340] ----Total loss 1.872002124786377\n","---- [Epoch 32/40, Batch 38/340] ----Total loss 1.512413501739502\n","---- [Epoch 32/40, Batch 39/340] ----Total loss 2.26522159576416\n","---- [Epoch 32/40, Batch 40/340] ----Total loss 2.9220967292785645\n","---- [Epoch 32/40, Batch 41/340] ----Total loss 1.3126686811447144\n","---- [Epoch 32/40, Batch 42/340] ----Total loss 1.4121299982070923\n","---- [Epoch 32/40, Batch 43/340] ----Total loss 1.08670973777771\n","---- [Epoch 32/40, Batch 44/340] ----Total loss 1.3703811168670654\n","---- [Epoch 32/40, Batch 45/340] ----Total loss 1.0314408540725708\n","---- [Epoch 32/40, Batch 46/340] ----Total loss 3.618450403213501\n","---- [Epoch 32/40, Batch 47/340] ----Total loss 2.7654294967651367\n","---- [Epoch 32/40, Batch 48/340] ----Total loss 1.7026032209396362\n","---- [Epoch 32/40, Batch 49/340] ----Total loss 0.859483003616333\n","---- [Epoch 32/40, Batch 50/340] ----Total loss 1.7767515182495117\n","---- [Epoch 32/40, Batch 51/340] ----Total loss 1.3698561191558838\n","---- [Epoch 32/40, Batch 52/340] ----Total loss 2.160301685333252\n","---- [Epoch 32/40, Batch 53/340] ----Total loss 1.8138186931610107\n","---- [Epoch 32/40, Batch 54/340] ----Total loss 1.89652681350708\n","---- [Epoch 32/40, Batch 55/340] ----Total loss 1.3659502267837524\n","---- [Epoch 32/40, Batch 56/340] ----Total loss 1.0679712295532227\n","---- [Epoch 32/40, Batch 57/340] ----Total loss 2.322960376739502\n","---- [Epoch 32/40, Batch 58/340] ----Total loss 1.7676386833190918\n","---- [Epoch 32/40, Batch 59/340] ----Total loss 2.411558151245117\n","---- [Epoch 32/40, Batch 60/340] ----Total loss 1.105887770652771\n","---- [Epoch 32/40, Batch 61/340] ----Total loss 1.066165804862976\n","---- [Epoch 32/40, Batch 62/340] ----Total loss 2.0010721683502197\n","---- [Epoch 32/40, Batch 63/340] ----Total loss 1.5001369714736938\n","---- [Epoch 32/40, Batch 64/340] ----Total loss 1.6828913688659668\n","---- [Epoch 32/40, Batch 65/340] ----Total loss 1.1831767559051514\n","---- [Epoch 32/40, Batch 66/340] ----Total loss 2.368048667907715\n","---- [Epoch 32/40, Batch 67/340] ----Total loss 1.6344834566116333\n","---- [Epoch 32/40, Batch 68/340] ----Total loss 1.2532007694244385\n","---- [Epoch 32/40, Batch 69/340] ----Total loss 3.789076805114746\n","---- [Epoch 32/40, Batch 70/340] ----Total loss 1.283847451210022\n","---- [Epoch 32/40, Batch 71/340] ----Total loss 1.7745262384414673\n","---- [Epoch 32/40, Batch 72/340] ----Total loss 1.968705654144287\n","---- [Epoch 32/40, Batch 73/340] ----Total loss 1.2128089666366577\n","---- [Epoch 32/40, Batch 74/340] ----Total loss 1.6186398267745972\n","---- [Epoch 32/40, Batch 75/340] ----Total loss 1.2913302183151245\n","---- [Epoch 32/40, Batch 76/340] ----Total loss 1.805071234703064\n","---- [Epoch 32/40, Batch 77/340] ----Total loss 1.237865686416626\n","---- [Epoch 32/40, Batch 78/340] ----Total loss 1.327889323234558\n","---- [Epoch 32/40, Batch 79/340] ----Total loss 1.5045485496520996\n","---- [Epoch 32/40, Batch 80/340] ----Total loss 1.1060184240341187\n","---- [Epoch 32/40, Batch 81/340] ----Total loss 1.2444792985916138\n","---- [Epoch 32/40, Batch 82/340] ----Total loss 1.04049551486969\n","---- [Epoch 32/40, Batch 83/340] ----Total loss 1.1550421714782715\n","---- [Epoch 32/40, Batch 84/340] ----Total loss 0.92735755443573\n","---- [Epoch 32/40, Batch 85/340] ----Total loss 2.4090917110443115\n","---- [Epoch 32/40, Batch 86/340] ----Total loss 1.4101588726043701\n","---- [Epoch 32/40, Batch 87/340] ----Total loss 1.3603777885437012\n","---- [Epoch 32/40, Batch 88/340] ----Total loss 2.0623016357421875\n","---- [Epoch 32/40, Batch 89/340] ----Total loss 1.6905970573425293\n","---- [Epoch 32/40, Batch 90/340] ----Total loss 2.3669686317443848\n","---- [Epoch 32/40, Batch 91/340] ----Total loss 1.5146158933639526\n","---- [Epoch 32/40, Batch 92/340] ----Total loss 1.8297615051269531\n","---- [Epoch 32/40, Batch 93/340] ----Total loss 1.044764757156372\n","---- [Epoch 32/40, Batch 94/340] ----Total loss 1.5108774900436401\n","---- [Epoch 32/40, Batch 95/340] ----Total loss 1.6579082012176514\n","---- [Epoch 32/40, Batch 96/340] ----Total loss 2.7049381732940674\n","---- [Epoch 32/40, Batch 97/340] ----Total loss 3.2483201026916504\n","---- [Epoch 32/40, Batch 98/340] ----Total loss 1.0823357105255127\n","---- [Epoch 32/40, Batch 99/340] ----Total loss 2.0624749660491943\n","---- [Epoch 32/40, Batch 100/340] ----Total loss 2.357152223587036\n","---- [Epoch 32/40, Batch 101/340] ----Total loss 1.711418628692627\n","---- [Epoch 32/40, Batch 102/340] ----Total loss 3.6857922077178955\n","---- [Epoch 32/40, Batch 103/340] ----Total loss 1.0926775932312012\n","---- [Epoch 32/40, Batch 104/340] ----Total loss 1.927584171295166\n","---- [Epoch 32/40, Batch 105/340] ----Total loss 1.598419427871704\n","---- [Epoch 32/40, Batch 106/340] ----Total loss 2.8888816833496094\n","---- [Epoch 32/40, Batch 107/340] ----Total loss 1.2902381420135498\n","---- [Epoch 32/40, Batch 108/340] ----Total loss 1.835888385772705\n","---- [Epoch 32/40, Batch 109/340] ----Total loss 2.5978710651397705\n","---- [Epoch 32/40, Batch 110/340] ----Total loss 1.8353153467178345\n","---- [Epoch 32/40, Batch 111/340] ----Total loss 2.1175591945648193\n","---- [Epoch 32/40, Batch 112/340] ----Total loss 1.2002919912338257\n","---- [Epoch 32/40, Batch 113/340] ----Total loss 1.8660866022109985\n","---- [Epoch 32/40, Batch 114/340] ----Total loss 2.495086669921875\n","---- [Epoch 32/40, Batch 115/340] ----Total loss 2.7768094539642334\n","---- [Epoch 32/40, Batch 116/340] ----Total loss 0.9721099734306335\n","---- [Epoch 32/40, Batch 117/340] ----Total loss 2.870786428451538\n","---- [Epoch 32/40, Batch 118/340] ----Total loss 1.3346209526062012\n","---- [Epoch 32/40, Batch 119/340] ----Total loss 1.5234723091125488\n","---- [Epoch 32/40, Batch 120/340] ----Total loss 1.9263863563537598\n","---- [Epoch 32/40, Batch 121/340] ----Total loss 1.3108950853347778\n","---- [Epoch 32/40, Batch 122/340] ----Total loss 2.231637954711914\n","---- [Epoch 32/40, Batch 123/340] ----Total loss 2.6339378356933594\n","---- [Epoch 32/40, Batch 124/340] ----Total loss 2.8535313606262207\n","---- [Epoch 32/40, Batch 125/340] ----Total loss 2.1567482948303223\n","---- [Epoch 32/40, Batch 126/340] ----Total loss 1.5108189582824707\n","---- [Epoch 32/40, Batch 127/340] ----Total loss 1.3074208498001099\n","---- [Epoch 32/40, Batch 128/340] ----Total loss 2.140069007873535\n","---- [Epoch 32/40, Batch 129/340] ----Total loss 1.9075714349746704\n","---- [Epoch 32/40, Batch 130/340] ----Total loss 1.8191430568695068\n","---- [Epoch 32/40, Batch 131/340] ----Total loss 1.2901771068572998\n","---- [Epoch 32/40, Batch 132/340] ----Total loss 2.2703635692596436\n","---- [Epoch 32/40, Batch 133/340] ----Total loss 1.1918576955795288\n","---- [Epoch 32/40, Batch 134/340] ----Total loss 1.433175802230835\n","---- [Epoch 32/40, Batch 135/340] ----Total loss 1.4968910217285156\n","---- [Epoch 32/40, Batch 136/340] ----Total loss 1.1676932573318481\n","---- [Epoch 32/40, Batch 137/340] ----Total loss 1.2732579708099365\n","---- [Epoch 32/40, Batch 138/340] ----Total loss 2.4754438400268555\n","---- [Epoch 32/40, Batch 139/340] ----Total loss 1.3759080171585083\n","---- [Epoch 32/40, Batch 140/340] ----Total loss 1.17497980594635\n","---- [Epoch 32/40, Batch 141/340] ----Total loss 2.0307650566101074\n","---- [Epoch 32/40, Batch 142/340] ----Total loss 1.2030932903289795\n","---- [Epoch 32/40, Batch 143/340] ----Total loss 3.2800168991088867\n","---- [Epoch 32/40, Batch 144/340] ----Total loss 1.830754280090332\n","---- [Epoch 32/40, Batch 145/340] ----Total loss 3.467813014984131\n","---- [Epoch 32/40, Batch 146/340] ----Total loss 2.538360595703125\n","---- [Epoch 32/40, Batch 147/340] ----Total loss 1.3433595895767212\n","---- [Epoch 32/40, Batch 148/340] ----Total loss 1.204082727432251\n","---- [Epoch 32/40, Batch 149/340] ----Total loss 2.227278709411621\n","---- [Epoch 32/40, Batch 150/340] ----Total loss 1.5666314363479614\n","---- [Epoch 32/40, Batch 151/340] ----Total loss 1.486513614654541\n","---- [Epoch 32/40, Batch 152/340] ----Total loss 1.6936006546020508\n","---- [Epoch 32/40, Batch 153/340] ----Total loss 1.3919811248779297\n","---- [Epoch 32/40, Batch 154/340] ----Total loss 2.7613797187805176\n","---- [Epoch 32/40, Batch 155/340] ----Total loss 2.2367496490478516\n","---- [Epoch 32/40, Batch 156/340] ----Total loss 2.901242733001709\n","---- [Epoch 32/40, Batch 157/340] ----Total loss 1.9024605751037598\n","---- [Epoch 32/40, Batch 158/340] ----Total loss 2.545595407485962\n","---- [Epoch 32/40, Batch 159/340] ----Total loss 1.62102210521698\n","---- [Epoch 32/40, Batch 160/340] ----Total loss 3.0034427642822266\n","---- [Epoch 32/40, Batch 161/340] ----Total loss 1.7940953969955444\n","---- [Epoch 32/40, Batch 162/340] ----Total loss 3.626498222351074\n","---- [Epoch 32/40, Batch 163/340] ----Total loss 3.8805761337280273\n","---- [Epoch 32/40, Batch 164/340] ----Total loss 1.5190094709396362\n","---- [Epoch 32/40, Batch 165/340] ----Total loss 2.0992562770843506\n","---- [Epoch 32/40, Batch 166/340] ----Total loss 4.160597324371338\n","---- [Epoch 32/40, Batch 167/340] ----Total loss 1.826491355895996\n","---- [Epoch 32/40, Batch 168/340] ----Total loss 1.896960973739624\n","---- [Epoch 32/40, Batch 169/340] ----Total loss 1.2539560794830322\n","---- [Epoch 32/40, Batch 170/340] ----Total loss 1.3209483623504639\n","---- [Epoch 32/40, Batch 171/340] ----Total loss 2.4850382804870605\n","---- [Epoch 32/40, Batch 172/340] ----Total loss 1.4432001113891602\n","---- [Epoch 32/40, Batch 173/340] ----Total loss 2.9807143211364746\n","---- [Epoch 32/40, Batch 174/340] ----Total loss 2.0469765663146973\n","---- [Epoch 32/40, Batch 175/340] ----Total loss 2.459444522857666\n","---- [Epoch 32/40, Batch 176/340] ----Total loss 1.6815547943115234\n","---- [Epoch 32/40, Batch 177/340] ----Total loss 2.4611568450927734\n","---- [Epoch 32/40, Batch 178/340] ----Total loss 2.4510927200317383\n","---- [Epoch 32/40, Batch 179/340] ----Total loss 1.4166274070739746\n","---- [Epoch 32/40, Batch 180/340] ----Total loss 3.6943891048431396\n","---- [Epoch 32/40, Batch 181/340] ----Total loss 1.3286094665527344\n","---- [Epoch 32/40, Batch 182/340] ----Total loss 3.084893226623535\n","---- [Epoch 32/40, Batch 183/340] ----Total loss 2.734983444213867\n","---- [Epoch 32/40, Batch 184/340] ----Total loss 1.7209415435791016\n","---- [Epoch 32/40, Batch 185/340] ----Total loss 1.7170342206954956\n","---- [Epoch 32/40, Batch 186/340] ----Total loss 1.1581978797912598\n","---- [Epoch 32/40, Batch 187/340] ----Total loss 1.1685179471969604\n","---- [Epoch 32/40, Batch 188/340] ----Total loss 2.0114173889160156\n","---- [Epoch 32/40, Batch 189/340] ----Total loss 2.2065696716308594\n","---- [Epoch 32/40, Batch 190/340] ----Total loss 1.8253200054168701\n","---- [Epoch 32/40, Batch 191/340] ----Total loss 4.4296040534973145\n","---- [Epoch 32/40, Batch 192/340] ----Total loss 1.493471384048462\n","---- [Epoch 32/40, Batch 193/340] ----Total loss 1.8337738513946533\n","---- [Epoch 32/40, Batch 194/340] ----Total loss 1.959012746810913\n","---- [Epoch 32/40, Batch 195/340] ----Total loss 1.311579942703247\n","---- [Epoch 32/40, Batch 196/340] ----Total loss 2.999934196472168\n","---- [Epoch 32/40, Batch 197/340] ----Total loss 1.2158747911453247\n","---- [Epoch 32/40, Batch 198/340] ----Total loss 1.6170387268066406\n","---- [Epoch 32/40, Batch 199/340] ----Total loss 2.063990354537964\n","---- [Epoch 32/40, Batch 200/340] ----Total loss 3.0799007415771484\n","---- [Epoch 32/40, Batch 201/340] ----Total loss 1.969843864440918\n","---- [Epoch 32/40, Batch 202/340] ----Total loss 1.044192910194397\n","---- [Epoch 32/40, Batch 203/340] ----Total loss 1.7688783407211304\n","---- [Epoch 32/40, Batch 204/340] ----Total loss 1.5210410356521606\n","---- [Epoch 32/40, Batch 205/340] ----Total loss 1.4759299755096436\n","---- [Epoch 32/40, Batch 206/340] ----Total loss 1.7082390785217285\n","---- [Epoch 32/40, Batch 207/340] ----Total loss 3.62776517868042\n","---- [Epoch 32/40, Batch 208/340] ----Total loss 4.079896926879883\n","---- [Epoch 32/40, Batch 209/340] ----Total loss 2.264582633972168\n","---- [Epoch 32/40, Batch 210/340] ----Total loss 1.5724141597747803\n","---- [Epoch 32/40, Batch 211/340] ----Total loss 1.8263771533966064\n","---- [Epoch 32/40, Batch 212/340] ----Total loss 1.4550249576568604\n","---- [Epoch 32/40, Batch 213/340] ----Total loss 1.4624944925308228\n","---- [Epoch 32/40, Batch 214/340] ----Total loss 2.389153242111206\n","---- [Epoch 32/40, Batch 215/340] ----Total loss 2.7985568046569824\n","---- [Epoch 32/40, Batch 216/340] ----Total loss 2.624110460281372\n","---- [Epoch 32/40, Batch 217/340] ----Total loss 1.506344199180603\n","---- [Epoch 32/40, Batch 218/340] ----Total loss 2.226886749267578\n","---- [Epoch 32/40, Batch 219/340] ----Total loss 1.9949884414672852\n","---- [Epoch 32/40, Batch 220/340] ----Total loss 2.0276191234588623\n","---- [Epoch 32/40, Batch 221/340] ----Total loss 2.275012969970703\n","---- [Epoch 32/40, Batch 222/340] ----Total loss 1.2434736490249634\n","---- [Epoch 32/40, Batch 223/340] ----Total loss 2.1738665103912354\n","---- [Epoch 32/40, Batch 224/340] ----Total loss 1.5409815311431885\n","---- [Epoch 32/40, Batch 225/340] ----Total loss 1.324721097946167\n","---- [Epoch 32/40, Batch 226/340] ----Total loss 2.0177669525146484\n","---- [Epoch 32/40, Batch 227/340] ----Total loss 1.6945900917053223\n","---- [Epoch 32/40, Batch 228/340] ----Total loss 1.7235100269317627\n","---- [Epoch 32/40, Batch 229/340] ----Total loss 3.811397075653076\n","---- [Epoch 32/40, Batch 230/340] ----Total loss 1.653210163116455\n","---- [Epoch 32/40, Batch 231/340] ----Total loss 2.590083599090576\n","---- [Epoch 32/40, Batch 232/340] ----Total loss 1.3615176677703857\n","---- [Epoch 32/40, Batch 233/340] ----Total loss 1.4381616115570068\n","---- [Epoch 32/40, Batch 234/340] ----Total loss 3.514528512954712\n","---- [Epoch 32/40, Batch 235/340] ----Total loss 1.3891420364379883\n","---- [Epoch 32/40, Batch 236/340] ----Total loss 1.4971145391464233\n","---- [Epoch 32/40, Batch 237/340] ----Total loss 2.1101293563842773\n","---- [Epoch 32/40, Batch 238/340] ----Total loss 1.3917486667633057\n","---- [Epoch 32/40, Batch 239/340] ----Total loss 1.8072705268859863\n","---- [Epoch 32/40, Batch 240/340] ----Total loss 1.461124062538147\n","---- [Epoch 32/40, Batch 241/340] ----Total loss 0.9141727685928345\n","---- [Epoch 32/40, Batch 242/340] ----Total loss 3.4711945056915283\n","---- [Epoch 32/40, Batch 243/340] ----Total loss 1.451384425163269\n","---- [Epoch 32/40, Batch 244/340] ----Total loss 2.726001262664795\n","---- [Epoch 32/40, Batch 245/340] ----Total loss 1.4060033559799194\n","---- [Epoch 32/40, Batch 246/340] ----Total loss 1.2514632940292358\n","---- [Epoch 32/40, Batch 247/340] ----Total loss 1.627530813217163\n","---- [Epoch 32/40, Batch 248/340] ----Total loss 1.674774169921875\n","---- [Epoch 32/40, Batch 249/340] ----Total loss 1.0504181385040283\n","---- [Epoch 32/40, Batch 250/340] ----Total loss 1.3418409824371338\n","---- [Epoch 32/40, Batch 251/340] ----Total loss 1.1834383010864258\n","---- [Epoch 32/40, Batch 252/340] ----Total loss 1.4512428045272827\n","---- [Epoch 32/40, Batch 253/340] ----Total loss 1.2046074867248535\n","---- [Epoch 32/40, Batch 254/340] ----Total loss 1.5447627305984497\n","---- [Epoch 32/40, Batch 255/340] ----Total loss 1.612862229347229\n","---- [Epoch 32/40, Batch 256/340] ----Total loss 2.054790735244751\n","---- [Epoch 32/40, Batch 257/340] ----Total loss 1.682945966720581\n","---- [Epoch 32/40, Batch 258/340] ----Total loss 1.2423676252365112\n","---- [Epoch 32/40, Batch 259/340] ----Total loss 1.0279573202133179\n","---- [Epoch 32/40, Batch 260/340] ----Total loss 1.5701923370361328\n","---- [Epoch 32/40, Batch 261/340] ----Total loss 0.9708232879638672\n","---- [Epoch 32/40, Batch 262/340] ----Total loss 1.0131009817123413\n","---- [Epoch 32/40, Batch 263/340] ----Total loss 1.8940832614898682\n","---- [Epoch 32/40, Batch 264/340] ----Total loss 1.9822173118591309\n","---- [Epoch 32/40, Batch 265/340] ----Total loss 1.7571948766708374\n","---- [Epoch 32/40, Batch 266/340] ----Total loss 1.2184815406799316\n","---- [Epoch 32/40, Batch 267/340] ----Total loss 4.181201934814453\n","---- [Epoch 32/40, Batch 268/340] ----Total loss 1.2517207860946655\n","---- [Epoch 32/40, Batch 269/340] ----Total loss 1.340086579322815\n","---- [Epoch 32/40, Batch 270/340] ----Total loss 1.8406829833984375\n","---- [Epoch 32/40, Batch 271/340] ----Total loss 2.0472450256347656\n","---- [Epoch 32/40, Batch 272/340] ----Total loss 2.2466988563537598\n","---- [Epoch 32/40, Batch 273/340] ----Total loss 1.1522839069366455\n","---- [Epoch 32/40, Batch 274/340] ----Total loss 3.4287688732147217\n","---- [Epoch 32/40, Batch 275/340] ----Total loss 2.3968987464904785\n","---- [Epoch 32/40, Batch 276/340] ----Total loss 1.8836283683776855\n","---- [Epoch 32/40, Batch 277/340] ----Total loss 2.3314335346221924\n","---- [Epoch 32/40, Batch 278/340] ----Total loss 1.3373790979385376\n","---- [Epoch 32/40, Batch 279/340] ----Total loss 1.416727900505066\n","---- [Epoch 32/40, Batch 280/340] ----Total loss 1.2267789840698242\n","---- [Epoch 32/40, Batch 281/340] ----Total loss 1.3508484363555908\n","---- [Epoch 32/40, Batch 282/340] ----Total loss 1.887049913406372\n","---- [Epoch 32/40, Batch 283/340] ----Total loss 1.0168311595916748\n","---- [Epoch 32/40, Batch 284/340] ----Total loss 1.3774657249450684\n","---- [Epoch 32/40, Batch 285/340] ----Total loss 2.504862070083618\n","---- [Epoch 32/40, Batch 286/340] ----Total loss 2.1691675186157227\n","---- [Epoch 32/40, Batch 287/340] ----Total loss 3.6362085342407227\n","---- [Epoch 32/40, Batch 288/340] ----Total loss 1.6178388595581055\n","---- [Epoch 32/40, Batch 289/340] ----Total loss 1.9550522565841675\n","---- [Epoch 32/40, Batch 290/340] ----Total loss 0.9812538623809814\n","---- [Epoch 32/40, Batch 291/340] ----Total loss 0.864693284034729\n","---- [Epoch 32/40, Batch 292/340] ----Total loss 1.4153411388397217\n","---- [Epoch 32/40, Batch 293/340] ----Total loss 1.0448377132415771\n","---- [Epoch 32/40, Batch 294/340] ----Total loss 1.0890424251556396\n","---- [Epoch 32/40, Batch 295/340] ----Total loss 1.405683159828186\n","---- [Epoch 32/40, Batch 296/340] ----Total loss 1.5890058279037476\n","---- [Epoch 32/40, Batch 297/340] ----Total loss 1.5718600749969482\n","---- [Epoch 32/40, Batch 298/340] ----Total loss 1.895811915397644\n","---- [Epoch 32/40, Batch 299/340] ----Total loss 1.6131582260131836\n","---- [Epoch 32/40, Batch 300/340] ----Total loss 1.4366099834442139\n","---- [Epoch 32/40, Batch 301/340] ----Total loss 1.0595402717590332\n","---- [Epoch 32/40, Batch 302/340] ----Total loss 1.8230754137039185\n","---- [Epoch 32/40, Batch 303/340] ----Total loss 1.8462505340576172\n","---- [Epoch 32/40, Batch 304/340] ----Total loss 1.819469690322876\n","---- [Epoch 32/40, Batch 305/340] ----Total loss 1.6496100425720215\n","---- [Epoch 32/40, Batch 306/340] ----Total loss 1.1661102771759033\n","---- [Epoch 32/40, Batch 307/340] ----Total loss 2.8203983306884766\n","---- [Epoch 32/40, Batch 308/340] ----Total loss 1.5343101024627686\n","---- [Epoch 32/40, Batch 309/340] ----Total loss 1.8247003555297852\n","---- [Epoch 32/40, Batch 310/340] ----Total loss 1.8825929164886475\n","---- [Epoch 32/40, Batch 311/340] ----Total loss 1.1834352016448975\n","---- [Epoch 32/40, Batch 312/340] ----Total loss 1.7707574367523193\n","---- [Epoch 32/40, Batch 313/340] ----Total loss 1.3628510236740112\n","---- [Epoch 32/40, Batch 314/340] ----Total loss 1.054893136024475\n","---- [Epoch 32/40, Batch 315/340] ----Total loss 2.721301555633545\n","---- [Epoch 32/40, Batch 316/340] ----Total loss 1.121971845626831\n","---- [Epoch 32/40, Batch 317/340] ----Total loss 1.1703097820281982\n","---- [Epoch 32/40, Batch 318/340] ----Total loss 2.4101898670196533\n","---- [Epoch 32/40, Batch 319/340] ----Total loss 1.0819950103759766\n","---- [Epoch 32/40, Batch 320/340] ----Total loss 2.275510787963867\n","---- [Epoch 32/40, Batch 321/340] ----Total loss 2.081951379776001\n","---- [Epoch 32/40, Batch 322/340] ----Total loss 0.8037972450256348\n","---- [Epoch 32/40, Batch 323/340] ----Total loss 3.5066986083984375\n","---- [Epoch 32/40, Batch 324/340] ----Total loss 3.302246570587158\n","---- [Epoch 32/40, Batch 325/340] ----Total loss 2.216383695602417\n","---- [Epoch 32/40, Batch 326/340] ----Total loss 5.849038600921631\n","---- [Epoch 32/40, Batch 327/340] ----Total loss 1.1409432888031006\n","---- [Epoch 32/40, Batch 328/340] ----Total loss 1.8308452367782593\n","---- [Epoch 32/40, Batch 329/340] ----Total loss 1.828381896018982\n","---- [Epoch 32/40, Batch 330/340] ----Total loss 2.205911636352539\n","---- [Epoch 32/40, Batch 331/340] ----Total loss 1.2572216987609863\n","---- [Epoch 32/40, Batch 332/340] ----Total loss 3.0128235816955566\n","---- [Epoch 32/40, Batch 333/340] ----Total loss 1.450683355331421\n","---- [Epoch 32/40, Batch 334/340] ----Total loss 2.837841033935547\n","---- [Epoch 32/40, Batch 335/340] ----Total loss 1.259524941444397\n","---- [Epoch 32/40, Batch 336/340] ----Total loss 1.5026980638504028\n","---- [Epoch 32/40, Batch 337/340] ----Total loss 1.6466375589370728\n","---- [Epoch 32/40, Batch 338/340] ----Total loss 1.6394575834274292\n","---- [Epoch 32/40, Batch 339/340] ----Total loss 2.0877151489257812\n","---- [Epoch 33/40, Batch 0/340] ----Total loss 1.2839903831481934\n","---- [Epoch 33/40, Batch 1/340] ----Total loss 2.2238805294036865\n","---- [Epoch 33/40, Batch 2/340] ----Total loss 1.1490182876586914\n","---- [Epoch 33/40, Batch 3/340] ----Total loss 2.6906518936157227\n","---- [Epoch 33/40, Batch 4/340] ----Total loss 4.402712345123291\n","---- [Epoch 33/40, Batch 5/340] ----Total loss 1.382224440574646\n","---- [Epoch 33/40, Batch 6/340] ----Total loss 2.5542707443237305\n","---- [Epoch 33/40, Batch 7/340] ----Total loss 1.1229733228683472\n","---- [Epoch 33/40, Batch 8/340] ----Total loss 1.5443453788757324\n","---- [Epoch 33/40, Batch 9/340] ----Total loss 1.5778872966766357\n","---- [Epoch 33/40, Batch 10/340] ----Total loss 1.6968579292297363\n","---- [Epoch 33/40, Batch 11/340] ----Total loss 1.1278868913650513\n","---- [Epoch 33/40, Batch 12/340] ----Total loss 1.724328875541687\n","---- [Epoch 33/40, Batch 13/340] ----Total loss 2.293349504470825\n","---- [Epoch 33/40, Batch 14/340] ----Total loss 2.1512436866760254\n","---- [Epoch 33/40, Batch 15/340] ----Total loss 2.1899118423461914\n","---- [Epoch 33/40, Batch 16/340] ----Total loss 1.1801996231079102\n","---- [Epoch 33/40, Batch 17/340] ----Total loss 1.3329691886901855\n","---- [Epoch 33/40, Batch 18/340] ----Total loss 1.4120254516601562\n","---- [Epoch 33/40, Batch 19/340] ----Total loss 1.6083718538284302\n","---- [Epoch 33/40, Batch 20/340] ----Total loss 2.8369247913360596\n","---- [Epoch 33/40, Batch 21/340] ----Total loss 1.4293837547302246\n","---- [Epoch 33/40, Batch 22/340] ----Total loss 1.8404642343521118\n","---- [Epoch 33/40, Batch 23/340] ----Total loss 1.5610791444778442\n","---- [Epoch 33/40, Batch 24/340] ----Total loss 2.0111145973205566\n","---- [Epoch 33/40, Batch 25/340] ----Total loss 1.626876950263977\n","---- [Epoch 33/40, Batch 26/340] ----Total loss 2.5998647212982178\n","---- [Epoch 33/40, Batch 27/340] ----Total loss 2.640744209289551\n","---- [Epoch 33/40, Batch 28/340] ----Total loss 1.3961999416351318\n","---- [Epoch 33/40, Batch 29/340] ----Total loss 1.45183527469635\n","---- [Epoch 33/40, Batch 30/340] ----Total loss 2.897850513458252\n","---- [Epoch 33/40, Batch 31/340] ----Total loss 1.853029727935791\n","---- [Epoch 33/40, Batch 32/340] ----Total loss 1.9756968021392822\n","---- [Epoch 33/40, Batch 33/340] ----Total loss 1.734546184539795\n","---- [Epoch 33/40, Batch 34/340] ----Total loss 3.230339288711548\n","---- [Epoch 33/40, Batch 35/340] ----Total loss 2.5072240829467773\n","---- [Epoch 33/40, Batch 36/340] ----Total loss 1.4952812194824219\n","---- [Epoch 33/40, Batch 37/340] ----Total loss 1.931175708770752\n","---- [Epoch 33/40, Batch 38/340] ----Total loss 2.8422625064849854\n","---- [Epoch 33/40, Batch 39/340] ----Total loss 1.8853018283843994\n","---- [Epoch 33/40, Batch 40/340] ----Total loss 1.4872288703918457\n","---- [Epoch 33/40, Batch 41/340] ----Total loss 1.4091370105743408\n","---- [Epoch 33/40, Batch 42/340] ----Total loss 2.0404889583587646\n","---- [Epoch 33/40, Batch 43/340] ----Total loss 1.0523872375488281\n","---- [Epoch 33/40, Batch 44/340] ----Total loss 1.249155044555664\n","---- [Epoch 33/40, Batch 45/340] ----Total loss 1.353183388710022\n","---- [Epoch 33/40, Batch 46/340] ----Total loss 1.1435973644256592\n","---- [Epoch 33/40, Batch 47/340] ----Total loss 1.6938395500183105\n","---- [Epoch 33/40, Batch 48/340] ----Total loss 1.158452033996582\n","---- [Epoch 33/40, Batch 49/340] ----Total loss 1.2651832103729248\n","---- [Epoch 33/40, Batch 50/340] ----Total loss 1.756430745124817\n","---- [Epoch 33/40, Batch 51/340] ----Total loss 2.3413798809051514\n","---- [Epoch 33/40, Batch 52/340] ----Total loss 1.2717713117599487\n","---- [Epoch 33/40, Batch 53/340] ----Total loss 1.7279574871063232\n","---- [Epoch 33/40, Batch 54/340] ----Total loss 1.9451191425323486\n","---- [Epoch 33/40, Batch 55/340] ----Total loss 1.2655553817749023\n","---- [Epoch 33/40, Batch 56/340] ----Total loss 1.1279957294464111\n","---- [Epoch 33/40, Batch 57/340] ----Total loss 2.1825108528137207\n","---- [Epoch 33/40, Batch 58/340] ----Total loss 2.083995819091797\n","---- [Epoch 33/40, Batch 59/340] ----Total loss 1.317435383796692\n","---- [Epoch 33/40, Batch 60/340] ----Total loss 3.338423490524292\n","---- [Epoch 33/40, Batch 61/340] ----Total loss 3.175978660583496\n","---- [Epoch 33/40, Batch 62/340] ----Total loss 1.2249315977096558\n","---- [Epoch 33/40, Batch 63/340] ----Total loss 1.4415283203125\n","---- [Epoch 33/40, Batch 64/340] ----Total loss 1.9415898323059082\n","---- [Epoch 33/40, Batch 65/340] ----Total loss 2.6242101192474365\n","---- [Epoch 33/40, Batch 66/340] ----Total loss 1.3949484825134277\n","---- [Epoch 33/40, Batch 67/340] ----Total loss 1.4962917566299438\n","---- [Epoch 33/40, Batch 68/340] ----Total loss 1.3556092977523804\n","---- [Epoch 33/40, Batch 69/340] ----Total loss 1.699726939201355\n","---- [Epoch 33/40, Batch 70/340] ----Total loss 1.3555991649627686\n","---- [Epoch 33/40, Batch 71/340] ----Total loss 1.4844017028808594\n","---- [Epoch 33/40, Batch 72/340] ----Total loss 1.5567209720611572\n","---- [Epoch 33/40, Batch 73/340] ----Total loss 1.425873041152954\n","---- [Epoch 33/40, Batch 74/340] ----Total loss 1.4189636707305908\n","---- [Epoch 33/40, Batch 75/340] ----Total loss 2.4632508754730225\n","---- [Epoch 33/40, Batch 76/340] ----Total loss 3.0456666946411133\n","---- [Epoch 33/40, Batch 77/340] ----Total loss 1.4765225648880005\n","---- [Epoch 33/40, Batch 78/340] ----Total loss 2.6301941871643066\n","---- [Epoch 33/40, Batch 79/340] ----Total loss 1.7992477416992188\n","---- [Epoch 33/40, Batch 80/340] ----Total loss 1.0380209684371948\n","---- [Epoch 33/40, Batch 81/340] ----Total loss 1.1565468311309814\n","---- [Epoch 33/40, Batch 82/340] ----Total loss 1.7243534326553345\n","---- [Epoch 33/40, Batch 83/340] ----Total loss 2.6362924575805664\n","---- [Epoch 33/40, Batch 84/340] ----Total loss 1.31000816822052\n","---- [Epoch 33/40, Batch 85/340] ----Total loss 1.9136137962341309\n","---- [Epoch 33/40, Batch 86/340] ----Total loss 0.7308140993118286\n","---- [Epoch 33/40, Batch 87/340] ----Total loss 2.1787269115448\n","---- [Epoch 33/40, Batch 88/340] ----Total loss 1.6849284172058105\n","---- [Epoch 33/40, Batch 89/340] ----Total loss 1.531263828277588\n","---- [Epoch 33/40, Batch 90/340] ----Total loss 2.8085570335388184\n","---- [Epoch 33/40, Batch 91/340] ----Total loss 2.5180320739746094\n","---- [Epoch 33/40, Batch 92/340] ----Total loss 1.5462539196014404\n","---- [Epoch 33/40, Batch 93/340] ----Total loss 0.9857312440872192\n","---- [Epoch 33/40, Batch 94/340] ----Total loss 1.6314504146575928\n","---- [Epoch 33/40, Batch 95/340] ----Total loss 1.3317723274230957\n","---- [Epoch 33/40, Batch 96/340] ----Total loss 1.4161605834960938\n","---- [Epoch 33/40, Batch 97/340] ----Total loss 1.1659232378005981\n","---- [Epoch 33/40, Batch 98/340] ----Total loss 1.1263233423233032\n","---- [Epoch 33/40, Batch 99/340] ----Total loss 1.783085584640503\n","---- [Epoch 33/40, Batch 100/340] ----Total loss 1.6893136501312256\n","---- [Epoch 33/40, Batch 101/340] ----Total loss 1.5063872337341309\n","---- [Epoch 33/40, Batch 102/340] ----Total loss 1.3980971574783325\n","---- [Epoch 33/40, Batch 103/340] ----Total loss 1.7356481552124023\n","---- [Epoch 33/40, Batch 104/340] ----Total loss 2.5433192253112793\n","---- [Epoch 33/40, Batch 105/340] ----Total loss 1.4422204494476318\n","---- [Epoch 33/40, Batch 106/340] ----Total loss 1.5966951847076416\n","---- [Epoch 33/40, Batch 107/340] ----Total loss 2.2324414253234863\n","---- [Epoch 33/40, Batch 108/340] ----Total loss 1.975663661956787\n","---- [Epoch 33/40, Batch 109/340] ----Total loss 1.3604240417480469\n","---- [Epoch 33/40, Batch 110/340] ----Total loss 1.8968793153762817\n","---- [Epoch 33/40, Batch 111/340] ----Total loss 1.0972567796707153\n","---- [Epoch 33/40, Batch 112/340] ----Total loss 1.858445405960083\n","---- [Epoch 33/40, Batch 113/340] ----Total loss 1.7908636331558228\n","---- [Epoch 33/40, Batch 114/340] ----Total loss 1.7376198768615723\n","---- [Epoch 33/40, Batch 115/340] ----Total loss 1.0284605026245117\n","---- [Epoch 33/40, Batch 116/340] ----Total loss 1.574392318725586\n","---- [Epoch 33/40, Batch 117/340] ----Total loss 1.1945744752883911\n","---- [Epoch 33/40, Batch 118/340] ----Total loss 3.5758814811706543\n","---- [Epoch 33/40, Batch 119/340] ----Total loss 1.3519337177276611\n","---- [Epoch 33/40, Batch 120/340] ----Total loss 1.4496493339538574\n","---- [Epoch 33/40, Batch 121/340] ----Total loss 1.0937721729278564\n","---- [Epoch 33/40, Batch 122/340] ----Total loss 0.9787124395370483\n","---- [Epoch 33/40, Batch 123/340] ----Total loss 2.294813394546509\n","---- [Epoch 33/40, Batch 124/340] ----Total loss 1.2718812227249146\n","---- [Epoch 33/40, Batch 125/340] ----Total loss 0.8378061056137085\n","---- [Epoch 33/40, Batch 126/340] ----Total loss 1.6425367593765259\n","---- [Epoch 33/40, Batch 127/340] ----Total loss 1.554378628730774\n","---- [Epoch 33/40, Batch 128/340] ----Total loss 1.6006534099578857\n","---- [Epoch 33/40, Batch 129/340] ----Total loss 1.729942798614502\n","---- [Epoch 33/40, Batch 130/340] ----Total loss 3.303617000579834\n","---- [Epoch 33/40, Batch 131/340] ----Total loss 0.9402263760566711\n","---- [Epoch 33/40, Batch 132/340] ----Total loss 1.712960958480835\n","---- [Epoch 33/40, Batch 133/340] ----Total loss 1.7086892127990723\n","---- [Epoch 33/40, Batch 134/340] ----Total loss 1.2638767957687378\n","---- [Epoch 33/40, Batch 135/340] ----Total loss 1.739478349685669\n","---- [Epoch 33/40, Batch 136/340] ----Total loss 1.8490829467773438\n","---- [Epoch 33/40, Batch 137/340] ----Total loss 1.1917282342910767\n","---- [Epoch 33/40, Batch 138/340] ----Total loss 1.2561352252960205\n","---- [Epoch 33/40, Batch 139/340] ----Total loss 1.4342701435089111\n","---- [Epoch 33/40, Batch 140/340] ----Total loss 2.1810922622680664\n","---- [Epoch 33/40, Batch 141/340] ----Total loss 1.729599952697754\n","---- [Epoch 33/40, Batch 142/340] ----Total loss 1.3547226190567017\n","---- [Epoch 33/40, Batch 143/340] ----Total loss 1.0661907196044922\n","---- [Epoch 33/40, Batch 144/340] ----Total loss 1.6163337230682373\n","---- [Epoch 33/40, Batch 145/340] ----Total loss 1.726515769958496\n","---- [Epoch 33/40, Batch 146/340] ----Total loss 1.1455793380737305\n","---- [Epoch 33/40, Batch 147/340] ----Total loss 0.9520819187164307\n","---- [Epoch 33/40, Batch 148/340] ----Total loss 1.0913853645324707\n","---- [Epoch 33/40, Batch 149/340] ----Total loss 1.1256120204925537\n","---- [Epoch 33/40, Batch 150/340] ----Total loss 1.1575121879577637\n","---- [Epoch 33/40, Batch 151/340] ----Total loss 1.1501827239990234\n","---- [Epoch 33/40, Batch 152/340] ----Total loss 1.439237356185913\n","---- [Epoch 33/40, Batch 153/340] ----Total loss 2.214115619659424\n","---- [Epoch 33/40, Batch 154/340] ----Total loss 1.0538477897644043\n","---- [Epoch 33/40, Batch 155/340] ----Total loss 1.3594235181808472\n","---- [Epoch 33/40, Batch 156/340] ----Total loss 1.174626111984253\n","---- [Epoch 33/40, Batch 157/340] ----Total loss 1.2275433540344238\n","---- [Epoch 33/40, Batch 158/340] ----Total loss 2.8165173530578613\n","---- [Epoch 33/40, Batch 159/340] ----Total loss 1.0621187686920166\n","---- [Epoch 33/40, Batch 160/340] ----Total loss 0.7365015745162964\n","---- [Epoch 33/40, Batch 161/340] ----Total loss 1.742708683013916\n","---- [Epoch 33/40, Batch 162/340] ----Total loss 1.7325972318649292\n","---- [Epoch 33/40, Batch 163/340] ----Total loss 1.0911098718643188\n","---- [Epoch 33/40, Batch 164/340] ----Total loss 1.9006669521331787\n","---- [Epoch 33/40, Batch 165/340] ----Total loss 1.5318094491958618\n","---- [Epoch 33/40, Batch 166/340] ----Total loss 1.7301051616668701\n","---- [Epoch 33/40, Batch 167/340] ----Total loss 1.0839234590530396\n","---- [Epoch 33/40, Batch 168/340] ----Total loss 1.4535071849822998\n","---- [Epoch 33/40, Batch 169/340] ----Total loss 2.320537805557251\n","---- [Epoch 33/40, Batch 170/340] ----Total loss 1.652449607849121\n","---- [Epoch 33/40, Batch 171/340] ----Total loss 1.1002013683319092\n","---- [Epoch 33/40, Batch 172/340] ----Total loss 1.314473271369934\n","---- [Epoch 33/40, Batch 173/340] ----Total loss 1.7910487651824951\n","---- [Epoch 33/40, Batch 174/340] ----Total loss 1.5927681922912598\n","---- [Epoch 33/40, Batch 175/340] ----Total loss 1.9004604816436768\n","---- [Epoch 33/40, Batch 176/340] ----Total loss 1.4949142932891846\n","---- [Epoch 33/40, Batch 177/340] ----Total loss 1.987013816833496\n","---- [Epoch 33/40, Batch 178/340] ----Total loss 1.542039155960083\n","---- [Epoch 33/40, Batch 179/340] ----Total loss 2.308103561401367\n","---- [Epoch 33/40, Batch 180/340] ----Total loss 1.7288248538970947\n","---- [Epoch 33/40, Batch 181/340] ----Total loss 1.2224295139312744\n","---- [Epoch 33/40, Batch 182/340] ----Total loss 1.3051066398620605\n","---- [Epoch 33/40, Batch 183/340] ----Total loss 1.3024755716323853\n","---- [Epoch 33/40, Batch 184/340] ----Total loss 1.5151526927947998\n","---- [Epoch 33/40, Batch 185/340] ----Total loss 1.2303707599639893\n","---- [Epoch 33/40, Batch 186/340] ----Total loss 1.1365329027175903\n","---- [Epoch 33/40, Batch 187/340] ----Total loss 2.7205400466918945\n","---- [Epoch 33/40, Batch 188/340] ----Total loss 1.319623589515686\n","---- [Epoch 33/40, Batch 189/340] ----Total loss 2.60092830657959\n","---- [Epoch 33/40, Batch 190/340] ----Total loss 1.6029484272003174\n","---- [Epoch 33/40, Batch 191/340] ----Total loss 1.1981897354125977\n","---- [Epoch 33/40, Batch 192/340] ----Total loss 1.2887349128723145\n","---- [Epoch 33/40, Batch 193/340] ----Total loss 1.3601245880126953\n","---- [Epoch 33/40, Batch 194/340] ----Total loss 2.542059898376465\n","---- [Epoch 33/40, Batch 195/340] ----Total loss 1.7010524272918701\n","---- [Epoch 33/40, Batch 196/340] ----Total loss 1.2543081045150757\n","---- [Epoch 33/40, Batch 197/340] ----Total loss 1.5250232219696045\n","---- [Epoch 33/40, Batch 198/340] ----Total loss 1.213021159172058\n","---- [Epoch 33/40, Batch 199/340] ----Total loss 2.6111316680908203\n","---- [Epoch 33/40, Batch 200/340] ----Total loss 2.2521934509277344\n","---- [Epoch 33/40, Batch 201/340] ----Total loss 4.4139838218688965\n","---- [Epoch 33/40, Batch 202/340] ----Total loss 1.7236225605010986\n","---- [Epoch 33/40, Batch 203/340] ----Total loss 1.9090697765350342\n","---- [Epoch 33/40, Batch 204/340] ----Total loss 1.2737585306167603\n","---- [Epoch 33/40, Batch 205/340] ----Total loss 2.7743804454803467\n","---- [Epoch 33/40, Batch 206/340] ----Total loss 0.8997743725776672\n","---- [Epoch 33/40, Batch 207/340] ----Total loss 0.9758098125457764\n","---- [Epoch 33/40, Batch 208/340] ----Total loss 1.6118476390838623\n","---- [Epoch 33/40, Batch 209/340] ----Total loss 1.4500296115875244\n","---- [Epoch 33/40, Batch 210/340] ----Total loss 1.6910734176635742\n","---- [Epoch 33/40, Batch 211/340] ----Total loss 1.364104986190796\n","---- [Epoch 33/40, Batch 212/340] ----Total loss 0.8376167416572571\n","---- [Epoch 33/40, Batch 213/340] ----Total loss 1.9634290933609009\n","---- [Epoch 33/40, Batch 214/340] ----Total loss 2.5743751525878906\n","---- [Epoch 33/40, Batch 215/340] ----Total loss 2.462116241455078\n","---- [Epoch 33/40, Batch 216/340] ----Total loss 1.2754714488983154\n","---- [Epoch 33/40, Batch 217/340] ----Total loss 1.4014902114868164\n","---- [Epoch 33/40, Batch 218/340] ----Total loss 2.1264915466308594\n","---- [Epoch 33/40, Batch 219/340] ----Total loss 1.3115506172180176\n","---- [Epoch 33/40, Batch 220/340] ----Total loss 1.4645395278930664\n","---- [Epoch 33/40, Batch 221/340] ----Total loss 7.472458839416504\n","---- [Epoch 33/40, Batch 222/340] ----Total loss 1.3880600929260254\n","---- [Epoch 33/40, Batch 223/340] ----Total loss 1.7402844429016113\n","---- [Epoch 33/40, Batch 224/340] ----Total loss 1.9885706901550293\n","---- [Epoch 33/40, Batch 225/340] ----Total loss 1.3266661167144775\n","---- [Epoch 33/40, Batch 226/340] ----Total loss 1.7938690185546875\n","---- [Epoch 33/40, Batch 227/340] ----Total loss 2.1702237129211426\n","---- [Epoch 33/40, Batch 228/340] ----Total loss 1.4931535720825195\n","---- [Epoch 33/40, Batch 229/340] ----Total loss 1.5616813898086548\n","---- [Epoch 33/40, Batch 230/340] ----Total loss 1.559006690979004\n","---- [Epoch 33/40, Batch 231/340] ----Total loss 1.663588047027588\n","---- [Epoch 33/40, Batch 232/340] ----Total loss 1.375268816947937\n","---- [Epoch 33/40, Batch 233/340] ----Total loss 1.4013869762420654\n","---- [Epoch 33/40, Batch 234/340] ----Total loss 2.1087262630462646\n","---- [Epoch 33/40, Batch 235/340] ----Total loss 1.5132389068603516\n","---- [Epoch 33/40, Batch 236/340] ----Total loss 1.2775150537490845\n","---- [Epoch 33/40, Batch 237/340] ----Total loss 1.683270812034607\n","---- [Epoch 33/40, Batch 238/340] ----Total loss 2.24749493598938\n","---- [Epoch 33/40, Batch 239/340] ----Total loss 1.618935227394104\n","---- [Epoch 33/40, Batch 240/340] ----Total loss 2.0740537643432617\n","---- [Epoch 33/40, Batch 241/340] ----Total loss 1.7710609436035156\n","---- [Epoch 33/40, Batch 242/340] ----Total loss 1.2637293338775635\n","---- [Epoch 33/40, Batch 243/340] ----Total loss 2.059332847595215\n","---- [Epoch 33/40, Batch 244/340] ----Total loss 1.3197894096374512\n","---- [Epoch 33/40, Batch 245/340] ----Total loss 1.1006476879119873\n","---- [Epoch 33/40, Batch 246/340] ----Total loss 2.219160556793213\n","---- [Epoch 33/40, Batch 247/340] ----Total loss 3.309988498687744\n","---- [Epoch 33/40, Batch 248/340] ----Total loss 1.443896770477295\n","---- [Epoch 33/40, Batch 249/340] ----Total loss 1.5399913787841797\n","---- [Epoch 33/40, Batch 250/340] ----Total loss 1.930537462234497\n","---- [Epoch 33/40, Batch 251/340] ----Total loss 2.3063201904296875\n","---- [Epoch 33/40, Batch 252/340] ----Total loss 1.3371933698654175\n","---- [Epoch 33/40, Batch 253/340] ----Total loss 1.375805377960205\n","---- [Epoch 33/40, Batch 254/340] ----Total loss 1.5080361366271973\n","---- [Epoch 33/40, Batch 255/340] ----Total loss 2.331512212753296\n","---- [Epoch 33/40, Batch 256/340] ----Total loss 2.304431438446045\n","---- [Epoch 33/40, Batch 257/340] ----Total loss 1.0607655048370361\n","---- [Epoch 33/40, Batch 258/340] ----Total loss 1.1597696542739868\n","---- [Epoch 33/40, Batch 259/340] ----Total loss 1.5416247844696045\n","---- [Epoch 33/40, Batch 260/340] ----Total loss 1.8107023239135742\n","---- [Epoch 33/40, Batch 261/340] ----Total loss 2.706721782684326\n","---- [Epoch 33/40, Batch 262/340] ----Total loss 3.607361078262329\n","---- [Epoch 33/40, Batch 263/340] ----Total loss 3.0966367721557617\n","---- [Epoch 33/40, Batch 264/340] ----Total loss 1.2944611310958862\n","---- [Epoch 33/40, Batch 265/340] ----Total loss 1.628230094909668\n","---- [Epoch 33/40, Batch 266/340] ----Total loss 1.2239279747009277\n","---- [Epoch 33/40, Batch 267/340] ----Total loss 2.008518695831299\n","---- [Epoch 33/40, Batch 268/340] ----Total loss 1.4314851760864258\n","---- [Epoch 33/40, Batch 269/340] ----Total loss 2.7872462272644043\n"],"name":"stdout"}]}]}